{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpu-notice"
   },
   "source": [
    "# Free EPUB to Audiobook Converter using KOKORO TTS\n",
    "\n",
    "## ⚡ IMPORTANT: Enable GPU Runtime\n",
    "\n",
    "**Before running this notebook:**\n",
    "1. Go to **Runtime → Change runtime type → Hardware accelerator → GPU**\n",
    "2. Click **Save**\n",
    "\n",
    "### Performance Benefits:\n",
    "- **With GPU:** 500 pages ≈ 16-18 minutes\n",
    "- **Without GPU:** 500 pages ≈ 90+ minutes (6x slower!)\n",
    "\n",
    "### What This Notebook Does:\n",
    "1. **Extract text** from EPUB files\n",
    "2. **Convert text to speech** using KOKORO TTS (creates multiple WAV files)\n",
    "3. **Combine WAV files** into a single audiobook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-epub-libs"
   },
   "outputs": [],
   "source": [
    "# Install required libraries for EPUB processing\n",
    "!pip install ebooklib beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-epub-libs"
   },
   "outputs": [],
   "source": [
    "from ebooklib import epub, ITEM_DOCUMENT\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def epub_to_text(epub_path):\n",
    "    \"\"\"\n",
    "    Extracts plain text from an EPUB file.\n",
    "    \n",
    "    Args:\n",
    "        epub_path (str): Path to the EPUB file\n",
    "        \n",
    "    Returns:\n",
    "        str: Complete text content of the EPUB\n",
    "    \"\"\"\n",
    "    # Read the EPUB file\n",
    "    book = epub.read_epub(epub_path)\n",
    "    \n",
    "    texts = []\n",
    "    \n",
    "    # Iterate through all items in the EPUB\n",
    "    for item in book.get_items():\n",
    "        # Filter for document items (actual content)\n",
    "        if item.get_type() == ITEM_DOCUMENT:\n",
    "            # Parse HTML content using BeautifulSoup\n",
    "            soup = BeautifulSoup(item.get_content(), \"html.parser\")\n",
    "            \n",
    "            # Extract clean text, removing HTML tags\n",
    "            text = soup.get_text(separator=\" \", strip=True)\n",
    "            \n",
    "            # Add non-empty text to our collection\n",
    "            if text:\n",
    "                texts.append(text)\n",
    "    \n",
    "    # Join all text chunks with double newlines for paragraph separation\n",
    "    return \"\\n\\n\".join(texts)\n",
    "\n",
    "# Path to your EPUB file - UPDATE THIS with your actual file path\n",
    "epub_path = \"/content/Higher Vibrations for Health, Happine... (Z-Library).epub\"\n",
    "\n",
    "# Extract text from EPUB\n",
    "full_text = epub_to_text(epub_path)\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"Total characters: {len(full_text)}\")\n",
    "print(full_text[:2000])  # Show first 2000 characters as preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chunking-section"
   },
   "source": [
    "## Text Chunking\n",
    "\n",
    "The text is split into smaller chunks to:\n",
    "- Stay within TTS model input limits\n",
    "- Allow progress tracking\n",
    "- Enable parallel processing if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chunk-text"
   },
   "outputs": [],
   "source": [
    "def chunk_text(text, max_chars=1000):\n",
    "    \"\"\"\n",
    "    Splits text into manageable chunks for TTS processing.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Full text to chunk\n",
    "        max_chars (int): Maximum characters per chunk\n",
    "        \n",
    "    Returns:\n",
    "        list: List of text chunks\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    current = \"\"\n",
    "    \n",
    "    # Split by sentences to maintain natural breaks\n",
    "    for sentence in text.split(\". \"):\n",
    "        # Check if adding this sentence would exceed the limit\n",
    "        if len(current) + len(sentence) < max_chars:\n",
    "            current += sentence + \". \"\n",
    "        else:\n",
    "            # Save current chunk and start new one\n",
    "            chunks.append(current.strip())\n",
    "            current = sentence + \". \"\n",
    "    \n",
    "    # Add the final chunk if it's not empty\n",
    "    if current.strip():\n",
    "        chunks.append(current.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Split the full text into chunks\n",
    "chunks = chunk_text(full_text)\n",
    "print(f\"Total chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tts-section"
   },
   "source": [
    "## Text-to-Speech Conversion\n",
    "\n",
    "This section uses **KOKORO TTS** to convert text chunks into audio.\n",
    "\n",
    "### What Happens:\n",
    "- Each text chunk is processed individually\n",
    "- Multiple WAV files are created (one per chunk)\n",
    "- Audio segments are stored for later combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-tts"
   },
   "outputs": [],
   "source": [
    "# Install KOKORO TTS and audio processing libraries\n",
    "!pip install kokoro torch soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init-tts"
   },
   "outputs": [],
   "source": [
    "from kokoro import KPipeline\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "# Initialize the KOKORO TTS pipeline\n",
    "# lang_code=\"a\" = American English\n",
    "# Other options: 'b' (British), 'f' (French), 'g' (German), 'i' (Italian), 'j' (Japanese), etc.\n",
    "pipeline = KPipeline(lang_code=\"a\")\n",
    "\n",
    "# Store all audio segments\n",
    "all_audio = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TEXT-TO-SPEECH CONVERSION\")\n",
    "print(\"This will create multiple WAV files, one for each chunk\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "process-chunks"
   },
   "outputs": [],
   "source": [
    "# Process each text chunk and convert to speech\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"Processing chunk {idx+1}/{len(chunks)}\")\n",
    "    \n",
    "    # Generate audio using KOKORO TTS\n",
    "    # voice=\"af_heart\" uses a female American English voice\n",
    "    generator = pipeline(chunk, voice=\"af_heart\")\n",
    "    \n",
    "    # Process the generated audio segments\n",
    "    for _, _, audio in generator:\n",
    "        all_audio.append(audio)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMBINING ALL AUDIO CHUNKS INTO SINGLE FILE\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "combine-audio"
   },
   "source": [
    "## Combine Audio Files\n",
    "\n",
    "All individual audio chunks are now combined into a single audiobook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-audiobook"
   },
   "outputs": [],
   "source": [
    "# Concatenate all audio segments into one waveform\n",
    "final_audio = np.concatenate(all_audio)\n",
    "\n",
    "# Save the complete audiobook as WAV file\n",
    "sf.write(\"audiobook.wav\", final_audio, 24000)\n",
    "print(\"✓ Complete audiobook saved as 'audiobook.wav'\")\n",
    "\n",
    "# Convert WAV to M4B format (audiobook format compatible with most players)\n",
    "print(\"\\nConverting to M4B format for better compatibility...\")\n",
    "!ffmpeg -i audiobook.wav -c:a aac -b:a 48k audiobook.m4b\n",
    "print(\"✓ Audiobook saved as 'audiobook.m4b'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "completion-notice"
   },
   "source": [
    "## ✅ Processing Complete!\n",
    "\n",
    "Your audiobook files are ready:\n",
    "- **audiobook.wav** - High quality WAV format\n",
    "- **audiobook.m4b** - Compressed M4B format for easy sharing\n",
    "\n",
    "### Download Instructions:\n",
    "1. Look at the file browser on the left side of Colab\n",
    "2. Find `audiobook.wav` and `audiobook.m4b`\n",
    "3. Right-click and select \"Download\"\n",
    "\n",
    "### Processing Summary:\n",
    "- **Input:** EPUB file with ~500 pages\n",
    "- **Output:** Complete audiobook in multiple formats\n",
    "- **Processing time:** ~16-18 minutes with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alternative-method"
   },
   "source": [
    "## Alternative Method: Individual WAV Files\n",
    "\n",
    "This section shows how to create and combine individual WAV files for each segment.\n",
    "Useful if you want to:\n",
    "- Review individual segments\n",
    "- Edit specific parts\n",
    "- Process segments separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alt-install"
   },
   "outputs": [],
   "source": [
    "# Install required system packages\n",
    "!apt-get -qq -y install espeak-ng > /dev/null 2>&1\n",
    "!pip install kokoro torch PyPDF2 soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alt-imports"
   },
   "outputs": [],
   "source": [
    "from kokoro import KPipeline\n",
    "from IPython.display import display, Audio\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "# Initialize the Kokoro TTS pipeline\n",
    "# 'a' = American English. You can switch this later to 'b' (British), 'f' (French), etc.\n",
    "pipeline = KPipeline(lang_code='a')\n",
    "\n",
    "# Sample text for demonstration\n",
    "text = '''This is the first short test paragraph. It introduces the idea clearly and simply.\n",
    "\n",
    "This is the second paragraph. It adds a small amount of continuation without extra detail.\n",
    "\n",
    "This is the third paragraph. It closes the example in a clean, minimal way.\n",
    "'''\n",
    "\n",
    "print(\"Processing sample text and creating individual WAV files...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-segments"
   },
   "outputs": [],
   "source": [
    "# Generate audio and save each segment as a separate WAV file\n",
    "generator = pipeline(text, voice='af_heart')\n",
    "\n",
    "for i, (gs, ps, audio) in enumerate(generator):\n",
    "    print(f\"Creating segment {i}.wav\")\n",
    "    print(\"Graphemes:\", gs)\n",
    "    print(\"Phonemes:\", ps)\n",
    "    \n",
    "    # Display audio player in notebook\n",
    "    display(Audio(data=audio, rate=24000, autoplay=False))\n",
    "    \n",
    "    # Save individual WAV file\n",
    "    sf.write(f'segment_{i}.wav', audio, 24000)\n",
    "\n",
    "print(\"\\n✓ Individual WAV files created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "combine-function"
   },
   "source": [
    "## Combine WAV Files Function\n",
    "\n",
    "This function combines multiple WAV files into a single audiobook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "define-combine-function"
   },
   "outputs": [],
   "source": [
    "# Function to combine multiple WAV files into a single file\n",
    "def combine_wav_files(file_prefix, output_filename=\"combined_audiobook.wav\"):\n",
    "    \"\"\"\n",
    "    Combines multiple WAV files with a common prefix into a single WAV file.\n",
    "    \n",
    "    Args:\n",
    "        file_prefix (str): Prefix of WAV files to combine (e.g., 'segment_' for segment_0.wav, segment_1.wav)\n",
    "        output_filename (str): Name of the output combined WAV file\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    import soundfile as sf\n",
    "    \n",
    "    # Find all WAV files matching the prefix\n",
    "    wav_files = sorted(glob.glob(f\"{file_prefix}*.wav\"))\n",
    "    \n",
    "    if not wav_files:\n",
    "        print(f\"No WAV files found with prefix '{file_prefix}'\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nFound {len(wav_files)} WAV files to combine:\")\n",
    "    for file in wav_files:\n",
    "        print(f\"  - {file}\")\n",
    "    \n",
    "    # Read and combine all audio files\n",
    "    combined_audio = []\n",
    "    sample_rate = None\n",
    "    \n",
    "    for wav_file in wav_files:\n",
    "        audio, sr = sf.read(wav_file)\n",
    "        if sample_rate is None:\n",
    "            sample_rate = sr\n",
    "        combined_audio.append(audio)\n",
    "        print(f\"✓ Loaded {wav_file} ({len(audio)} samples)\")\n",
    "    \n",
    "    # Concatenate all audio arrays\n",
    "    final_audio = np.concatenate(combined_audio)\n",
    "    \n",
    "    # Save the combined audio\n",
    "    sf.write(output_filename, final_audio, sample_rate)\n",
    "    print(f\"\\n✓ Combined audiobook saved as '{output_filename}'\")\n",
    "    print(f\"  Total samples: {len(final_audio)}\")\n",
    "    print(f\"  Duration: {len(final_audio)/sample_rate:.2f} seconds\")\n",
    "    \n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "combine-segments"
   },
   "outputs": [],
   "source": [
    "# Combine the individual segment files\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMBINING INDIVIDUAL WAV FILES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "combined_file = combine_wav_files(\"segment_\", \"final_audiobook.wav\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL TASKS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nYour audiobook files are ready:\")\n",
    "print(\"  - audiobook.wav (direct method)\")\n",
    "print(\"  - audiobook.m4b (M4B format)\")\n",
    "print(f\"  - {combined_file} (combined from segments)\")\n",
    "print(\"\\nYou can download these files from the Colab file browser on the left.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
